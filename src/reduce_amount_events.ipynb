{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import matplotlib.patches as mpatches\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import numpy as np\n",
    "import utils\n",
    "\n",
    "\n",
    "url_data = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15\n",
      "2\n",
      "8\n",
      "6\n",
      "15\n",
      "2\n",
      "8\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "speed_high = 15\n",
    "speed_low = 2\n",
    "speed_moderate_down = 6\n",
    "speed_moderate_up = 8\n",
    "utils.set_speed(speed_high,speed_low,speed_moderate_down,speed_moderate_up)\n",
    "\n",
    "print(utils.speed_high)\n",
    "print(utils.speed_low)\n",
    "print(utils.speed_moderate_up)\n",
    "print(utils.speed_moderate_down)\n",
    "\n",
    "utils.get_speeds()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count number of events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_cut = 96\n",
    "path_save = os.path.join(url_data,\"dataset_split_events\")\n",
    "\n",
    "years = [\"2000\",\"2001\",\"2002\",\"2003\",\"2004\",\"2005\",\"2006\",\"2007\",\"2008\",\"2009\",\\\n",
    "         \"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\",\"2018\",\"2019\",\"2020\"]\n",
    "\n",
    "for year in years:\n",
    "    print(year)\n",
    "    try:\n",
    "        print(utils.count_event_per_file(os.path.join(url_data,\"dataset_split_events\",f\"{year}_{range_cut}_15_high.csv\"))['events'].sum())\n",
    "    except:\n",
    "        print(\"empty csv\")\n",
    "    try:\n",
    "        print(utils.count_event_per_file(os.path.join(url_data,\"dataset_split_events\",f\"{year}_{range_cut}_moderate.csv\"))['events'].sum())\n",
    "    except:\n",
    "        print(\"empty csv\")\n",
    "    try:\n",
    "        print(utils.count_event_per_file(os.path.join(url_data,\"dataset_split_events\",f\"{year}_{range_cut}_low.csv\"))['events'].sum())\n",
    "    except:\n",
    "        print(\"empty csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split summer and winter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "ini_winder = datetime.strptime(\"2000-01-01 00:00:00\",'%Y-%m-%d %H:%M:%S')\n",
    "end_winter = datetime.strptime(\"2000-06-30 23:59:59\",'%Y-%m-%d %H:%M:%S')\n",
    "ini_summer = datetime.strptime(\"2000-07-01 00:00:00\",'%Y-%m-%d %H:%M:%S')\n",
    "end_summer = datetime.strptime(\"2000-12-31 23:59:59\",'%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "md_ini_winter = (ini_winder.month, ini_winder.day)\n",
    "md_end_winter = (end_winter.month, end_winter.day)\n",
    "md_ini_summer = (ini_summer.month, ini_summer.day)\n",
    "md_end_summer = (end_summer.month, end_summer.day)\n",
    "\n",
    "for file in os.listdir(\"../data/dataset_split_events/\"):\n",
    "    df = pl.read_csv(\"../data/dataset_split_events/\" + file)\n",
    "\n",
    "    cut_size = 96\n",
    "\n",
    "    middle = int(cut_size/2)\n",
    "\n",
    "    winter_df = pl.DataFrame()\n",
    "    summer_df = pl.DataFrame()\n",
    "\n",
    "    for windfarm in range(0,38):\n",
    "        # print(\"windfarm nº\",windfarm)\n",
    "        df_new = df.filter(pl.col(\"index\") == windfarm)\n",
    "        n_events = df_new[\"n_event\"].unique().shape[0]\n",
    "        # Compute number of rows in summer and in winter for the events in the middle\n",
    "\n",
    "        count_winter = 0\n",
    "        count_summer = 0\n",
    "\n",
    "        for event in range(0,n_events):\n",
    "            df_new_event = df_new.filter(pl.col(\"n_event\") == event)\n",
    "            time_split = datetime.strptime(df_new_event[middle,0],'%Y-%m-%d %H:%M:%S')\n",
    "            date_md = (time_split.month,time_split.day)\n",
    "\n",
    "            if md_ini_winter <= date_md <= md_end_winter:\n",
    "                df_new_event = df_new_event.with_column(pl.lit(count_winter).alias(\"n_event\"))\n",
    "                winter_df = pl.concat([winter_df,df_new_event], rechunk=True)\n",
    "                count_winter += 1 \n",
    "            else:\n",
    "                df_new_event = df_new_event.with_column(pl.lit(count_summer).alias(\"n_event\"))\n",
    "                summer_df = pl.concat([summer_df,df_new_event], rechunk=True)\n",
    "                count_summer += 1 \n",
    "\n",
    "    summer_df.write_csv(os.path.join(f\"../data/dataset_summer_split/\",f\"{file[:-4]}_summer.csv\"))\n",
    "    winter_df.write_csv(os.path.join(f\"../data/dataset_winter_split/\",f\"{file[:-4]}_winter.csv\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce low and Moderate to the amount of high"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe I have to change how i select the events and i did random\n",
    "- Random\n",
    "- Same distribution as high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "range_cut = 96\n",
    "\n",
    "years = [\"2000\",\"2006\",\"2009\",\"2010\",\"2013\",\"2014\",\"2017\"]\n",
    "kinds = [\"moderate\",\"low\"]\n",
    "path_read = os.path.join(url_data,\"dataset_split_events\")\n",
    "\n",
    "amount = [2385,3154,2204,3876,6387,3542,6037]\n",
    "\n",
    "for index,year in enumerate(years):\n",
    "    for kind in kinds:\n",
    "        n_to_take = int(amount[index]/38)\n",
    "        df = pl.read_csv(os.path.join(path_read,f\"{year}_{range_cut}_{kind}.csv\"))\n",
    "        new_df = pl.DataFrame()\n",
    "        for windfarm in range(0,38):\n",
    "            # print(\"windfarm nº\",windfarm)\n",
    "            df_new = df.filter(pl.col(\"index\") == windfarm)\n",
    "            n_events = df_new[\"n_event\"].unique().shape[0]\n",
    "            random_indices = random.sample(range(1,n_events+1), n_to_take)\n",
    "            df_selected = df_new.filter(df_new['n_event'].is_in(random_indices))\n",
    "            new_df = pl.concat([new_df,df_selected], rechunk=True)\n",
    "        new_df.write_csv(os.path.join(url_data,\"cut_dataset\",f\"{year}_{range_cut}_{kind}_cut.csv\"))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join cut in 3 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high\n",
      "2000\n",
      "2006\n",
      "2009\n",
      "2010\n",
      "2013\n",
      "2014\n",
      "2017\n",
      "moderate\n",
      "2000\n",
      "2006\n",
      "2009\n",
      "2010\n",
      "2013\n",
      "2014\n",
      "2017\n",
      "low\n",
      "2000\n",
      "2006\n",
      "2009\n",
      "2010\n",
      "2013\n",
      "2014\n",
      "2017\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(url_data,\"cut_dataset\")\n",
    "\n",
    "kinds = [\"high\",\"moderate\",\"low\"]\n",
    "years = [\"2000\",\"2006\",\"2009\",\"2010\",\"2013\",\"2014\",\"2017\"]\n",
    "\n",
    "range_cut = 96\n",
    "\n",
    "for kind in kinds:\n",
    "    print(kind)\n",
    "    new_df = pl.DataFrame()\n",
    "    for index,year in enumerate(years):\n",
    "        print(year)\n",
    "        if kind == \"high\":\n",
    "            df = pl.read_csv(os.path.join(path,f\"{year}_{range_cut}_15_{kind}.csv\"))\n",
    "        else:\n",
    "            df = pl.read_csv(os.path.join(path,f\"{year}_{range_cut}_{kind}_cut.csv\"))\n",
    "        df = df.with_column(pl.lit(year).alias(\"year\"))\n",
    "        # print(df.columns)\n",
    "        new_df = pl.concat([new_df,df], rechunk=True)\n",
    "        # print(new_df.columns)\n",
    "\n",
    "    new_df = new_df.select(['time', 'index', 'n_event', 'year', 'cc', 'o3', 'pv', 'cape', 'blh', 'd2m', 'z', 'relative_humidity', 't2m', 't100m', 't135m', 'wdir100m', 'wspeed135m', 'wspeed100m'])\n",
    "    new_df.write_csv(os.path.join(url_data,f\"final_files\",str(range_cut),f\"{kind}.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
